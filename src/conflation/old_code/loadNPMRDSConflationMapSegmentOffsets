#!/usr/bin/env node

/* eslint no-continue: 0 */

const { join } = require('path');
const { pipe, through } = require('mississippi');
const _ = require('lodash');
const { sync: rimrafSync } = require('rimraf');
const turf = require('@turf/turf');
const { point } = require('@turf/helpers');

const levelup = require('levelup');
const leveldown = require('leveldown');
const encode = require('encoding-down');

const KILOMETERS = {
  units: 'kilometers'
};

const SPLIT_BUFF_KM = 10 / 1000;

const CONFLATION_MAP_DB = join(__dirname, '../../data/leveldb/conflationMap/');

const SHST_MATCHED_NPMRDS_DB = join(
  __dirname,
  '../../data/leveldb/',
  'shstMatchedNpmrds'
);

const CONFLATION_MAPS_SEGEMENT_OFFSETS_DB = join(
  __dirname,
  '../../data/leveldb/',
  'conflationMapsSegmentOffsets'
);

const conflationMapDB = levelup(
  encode(leveldown(CONFLATION_MAP_DB), { valueEncoding: 'json' })
);

const shstMatchedTMCsDB = levelup(
  encode(leveldown(SHST_MATCHED_NPMRDS_DB), { valueEncoding: 'json' })
);

const conflationMapsSegmentsOffsetsDB = levelup(
  encode(leveldown(CONFLATION_MAPS_SEGEMENT_OFFSETS_DB), {
    valueEncoding: 'json'
  })
);

const tmcIsPrimary = require('./tmc_isprimary.json');

pipe(
  shstMatchedTMCsDB.createValueStream(),
  through.obj(async function loader(matches, $, cb) {
    // Collect the list of matched shstReferenceIds for this TMC
    const shstReferenceIds = [
      ...matches.reduce((acc, { properties: { shstReferenceId } }) => {
        if (shstReferenceId) {
          acc.add(shstReferenceId);
        }
        return acc;
      }, new Set())
    ];

    // Get the corresponding shstReference features for shstReference IDs
    //   as an object keyed by shstReferenceId
    const conflationMapFeatures = (await Promise.all(
      shstReferenceIds.map(async id => {
        try {
          const feature = await conflationMapDB.get(id);
          return { id, feature };
        } catch (err) {
          if (err.type === 'NotFoundError') {
            console.warn(
              `WARNING: no feature found in conflationMapDB for ${id}`
            );
            return null;
          }
          throw new Error(err);
        }
      })
    )).reduce((acc, d) => {
      if (d) {
        acc[d.id] = d.feature;
      }
      return acc;
    }, {});

    const conflationMapsSegmentOffsetsLists = (await Promise.all(
      shstReferenceIds.map(async id => {
        let list;

        // shstReference -> conflationMapsSegmentsOffset is 1-to-many
        try {
          list = await conflationMapsSegmentsOffsetsDB.get(id);
        } catch (err) {
          if (err.type === 'NotFoundError') {
            list = [];
          } else {
            console.error('conflationMapsSegmentsOffsetsDB.get');
            throw new Error(err);
          }
        }

        return { id, list };
      })
    )).reduce((acc, { id, list }) => {
      acc[id] = list;
      return acc;
    }, {});

    // For each shstMatch output feature
    for (let i = 0; i < matches.length; ++i) {
      const {
        properties: { shstReferenceId, pp_tmc: tmc, pp_f_system: fsystem },
        geometry: { coordinates: matchLineStringCoords }
      } = matches[i];

      // Disregard the nonprimary TMCs
      if (tmcIsPrimary[tmc] === 0) {
        continue;
      }

      // Get the match LineString endpoints
      const matchStartPtCoords = point(_.first(matchLineStringCoords));
      const matchEndPtCoords = point(_.last(matchLineStringCoords));

      // Get the shstReference feature
      const shstReferenceFeature = conflationMapFeatures[shstReferenceId];

      if (!shstReferenceFeature) {
        continue;
      }

      // the length of the shstReference for this match feature
      const geomLength = turf.length(shstReferenceFeature, KILOMETERS);

      // get the respective offset list for this match's shstReference
      const offsetList = conflationMapsSegmentOffsetsLists[shstReferenceId];

      const snappedStartPt = turf.nearestPointOnLine(
        shstReferenceFeature,
        matchStartPtCoords,
        KILOMETERS
      );
      const snappedEndPt = turf.nearestPointOnLine(
        shstReferenceFeature,
        matchEndPtCoords,
        KILOMETERS
      );

      const matchStartPtDistAlongShStRef = snappedStartPt.properties.location;
      const matchEndPtDistAlongShStRef = snappedEndPt.properties.location;

      if (matchStartPtDistAlongShStRef > matchEndPtDistAlongShStRef) {
        // Ignore. Small segment.
        if (matchStartPtDistAlongShStRef - matchEndPtDistAlongShStRef < SPLIT_BUFF_KM) {
          continue;
        }
        const m = JSON.stringify(matches, null, 4);
        const msg = `INVARIANT BROKEN: matchStartPtDistAlongShStRef > matchEndPtDistAlongShStRef\n${m}`;
        throw new Error(msg);
      }

      // This data object is what is used when splitting shstReferences
      //   while generating the output conflation map.
      const segmentOffsets = {
        shstReferenceId,
        geomLength,
        target_map: 'NPMRDS',
        target_map_id: tmc,
        fsystem,
        POFF: matchStartPtDistAlongShStRef,
        NOFF: geomLength - matchEndPtDistAlongShStRef,
        reversed: matchStartPtDistAlongShStRef > matchEndPtDistAlongShStRef
      };

      offsetList.push(segmentOffsets);
    }

    const batchPut = shstReferenceIds.map(id => ({
      type: 'put',
      key: id,
      value: _.uniqWith(conflationMapsSegmentOffsetsLists[id], _.isEqual)
    }));

    try {
      await conflationMapsSegmentsOffsetsDB.batch(batchPut);
    } catch (err) {
      console.error('ERROR in batch put');
      throw err;
    }

    return cb();
  }),
  err => {
    if (err) {
      console.error(
        'ERROR encountered while loading conflationMapsSegmentOffsets DB.'
      );
      console.error(
        `    Deleting the corruped database at ${CONFLATION_MAPS_SEGEMENT_OFFSETS_DB}`
      );
      console.error();
      console.error(err);
      rimrafSync(CONFLATION_MAPS_SEGEMENT_OFFSETS_DB);
      process.exit(1);
    }
  }
);
